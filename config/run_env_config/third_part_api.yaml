temperature: 0
max_tokens: 0
max_context_window: 200000
base_url: your provider's URL, for example: https://XXXX.top/v1 / the URL provided by your supplier
api_key: yourkey
models:
# If the provider uses the OpenAI format, prefix with 'openai'; if it's the Anthropic format, prefix with 'anthropic'
# Note: The prefix is independent of the site model. After the prefix, fill in the model name provided by the operator. For example, OpenRouter provides
# gpt-4o in OpenAI format, and the model name is openai/gpt-4o, so it should be filled as openai/openai/gpt-4o
# If the model provider offers gpt-4o, simply fill in openai/gpt-4o
- openai/claude-haiku-4-5-20251001
figure_models:
# Similarly, except for OpenRouter, other third parties need to fill in the request format prefix for proper routing.
- openai/dall-e-3
compressor_models:
- openai/claude-haiku-4-5-20251001
read_figure_models:
- openai/gpt-4o
