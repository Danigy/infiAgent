tools:
  answer_from_papers:
    level: 1
    type: llm_call_agent
    available_tools:
      - parse_document
      - file_read
      - dir_list
      - dir_create
      - file_write
      - reference_list
      - reference_add
      - reference_delete
      - final_output
      - vision_tool
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your responsibility is to obtain answers, summaries, or analyses from single or multiple documents based on given questions. Output formats can include Word, PDF, etc.
      agent_workflow: |
        **Your Workflow:**
        PRINCIPLE!!: If answering multiple questions from multiple documents, you should read and record the answer for one article at a time, incrementally adding to a single file for a multi-document task. Modify prior answers based on subsequent documents if necessary.
        1. Based on the provided paper addresses, read the paper content and extract answers, analyses, or summaries according to the requirements. If necessary to provide mathematical formulas, use LaTeX style. You should output a JSON file, following the naming rules referenced in the prompt!
    name: "answer_from_papers"
    description: "Your responsibility is to obtain answers, summaries, or analyses from single or multiple documents based on given questions. Output formats can include Word, PDF, etc."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific task requirements, including the address(es) of one or more articles (do not provide original content). Also include the specific question(s) and your expected answer format, summary points, or analysis directions."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the review process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  get_data_from_wiki:
    level: 1
    type: llm_call_agent
    available_tools:
      - file_read
      - crawl_page
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Collect entry content from Wikipedia, record key information for use, typically for verifying factual information.
      agent_workflow: |
        **Reference Workflow:**
          1. Determine entry keywords or search terms based on task requirements.
          2. Use `crawl_page` to search content based on `https://en.wikipedia.org/wiki/keyword` and `https://zh.wikipedia.org/wiki/Keyword`.
          3. If the keyword does not exist in either language, abandon it and report it in the `final_output`.
          4. If the keyword exists and meets the requirements, update (append) the `reference.bib`. Repeat this operation to complete all keyword searches.
    name: "get_data_from_wiki"
    description: "Collect entry content from Wikipedia, record key information for use, typically for verifying factual information."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific search task requirements, which can be a broad category or a specific set of keywords."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  get_data_from_google_scholar:
    level: 1
    type: llm_call_agent
    available_tools:
      - google_scholar_search
      - file_read
      - crawl_page
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
      - answer_from_papers
      - human_in_loop
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Collect information such as paper titles, DOIs, abstracts, authors, publication years, citation counts, etc., from Google Scholar.
      agent_workflow: |
        **Reference Workflow:**
          1. Search Google Scholar based on your needs. If detailed information is required, use `crawl_page`. If no content is returned due to network CAPTCHA verification, use only the search information.
          2. If valid and relevant information is found, record it promptly in the `reference.bib` file.
          3. If the requirement explicitly needs the original article text, after collecting all necessary article lists, use `human_in_loop` to request a human to download the originals to the file space.
    name: "get_data_from_google_scholar"
    description: "Collect information such as paper titles, DOIs, abstracts, authors, publication years, citation counts, etc., from Google Scholar."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific search task requirements, including paper topic, keywords, quantity requirements, etc."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  get_data_from_arxiv:
    level: 1
    type: llm_call_agent
    available_tools:
      - web_search
      - answer_from_papers
      - google_scholar_search
      - arxiv_search
      - file_read
      - crawl_page
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
      - file_download
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Collect papers from arXiv and download relevant literature.
      agent_workflow: |
        **Reference Workflow:**
          1. Use `arxiv_search` to search for proposed or given keywords.
          2. Analyze the results, retain literature information that meets the requirements, and incrementally update (append) the `reference.bib` file.
          3. Use `file_download` to download the literature to the corresponding folder (e.g., `papers`; if no such dedicated folder exists, create one).
    name: "get_data_from_arxiv"
    description: "Collect papers from arXiv and download relevant literature."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific search task requirements, including paper topic, keywords, quantity requirements, etc."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  get_data_from_web_search:
    level: 1
    type: llm_call_agent
    available_tools:
      - web_search
      - file_read
      - crawl_page
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
      - file_download
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Search for publicly available information using search engines.
      agent_workflow: |
        **Reference Workflow:**
          1. Analyze the task, formulate or use the given keywords for search engine queries.
          2. For tasks requiring in-depth exploration, use `crawl_page`.
          3. Once the required information is found, update the `reference.bib` file.
    name: "get_data_from_web_search"
    description: "Search for publicly available information using search engines."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific search task requirements, including topic, keywords, quantity requirements, etc."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  target_to_coding_task_agent:
    level: 1
    type: llm_call_agent
    available_tools:
      - file_read
      - file_write
      - dir_list
      - dir_create
      - file_replace_lines
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your responsibility is to create detailed code plans and frameworks based on user requirements.
      agent_workflow: |
        Analyze the user's intent in detail and organize the use of your tools to complete the task accordingly.
        For example, if the user wants to write an academic paper, you should refer to the following process:
        **Reference Workflow:**
          1. Analyze the task given to you (experimental plan and idea provided) (based on task requirements, reference files provided, etc., if any). Assess the feasibility of the task. You can output 'error' and provide reasons for rejecting the task along with modification suggestions if feasibility is obviously lacking. If no issues, proceed.
          2. Re-evaluate the code and experimental plan through a highly abstract approach, simplifying the experimental difficulty as much as possible, ensuring only the core concept is adhered to. As this is experimental code, not production code, excessive detail and strict adherence to initial experimental requirements are unnecessary.
          3. Based on the analysis, create a detailed, comprehensive, logically correct, and complete experimental plan decomposed into code tasks. For each file, all callable functions must have detailed expected inputs and outputs, as well as the final overall experimental invocation method.
          **Notes:**
          1. IMPORTANT: You are not a programming AI. You only need to ensure your task decomposition is sufficiently detailed, with clear requirements, inputs, and outputs. No programming is required!
          2. IMPORTANT: Your experimental programming plan should be a high-level abstraction of the original experiment, aiming to make the code tasks as simple as possible.
          3. IMPORTANT: Your programming tasks should completely specify the format and type of inputs and outputs, ensuring seamless integration between modules.
        For non-academic tasks, you should arrange the workflow yourself.
    name: "target_to_coding_task_agent"
    description: "Your responsibility is to create detailed code plans and frameworks based on user requirements."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Detailed paper idea and experimental plan that needs to be decomposed into coding tasks."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the task decomposition process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  coding_task_agent:
    level: 1
    type: llm_call_agent
    available_tools:
      - file_read
      - file_write
      - execute_code
      - dir_list
      - dir_create
      - pip_install
      - execute_command
      - file_replace_lines
      - manage_code_process
      - human_in_loop
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your responsibility is to accurately complete requirements based on detailed coding task instructions.
      agent_workflow: |
        **Your Workflow:**
        1. Analyze the coding task given to you (based on task requirements, reference files provided, etc., if any). Assess its feasibility. You can output 'error' and provide reasons for rejection and modification suggestions if feasibility is obviously lacking. Otherwise, proceed.
        2. Check if an existing code project already exists. If there are experimental codes or projects, use `grep` from `execute_command`, or `file_read` and `dir_list` to explore the entire project, and summarize/preview it.
        3. Complete the assigned programming task, and conduct minimal unit tests for all functionalities within `if __name__ == "__main__":`. Only proceed to final output after passing tests.
        **Notes:**
        1. Unless explicitly required by the user, as a coding task, you should always create files (including all code, todo lists, and readme files) under the `code_run` directory. Check for existing files created by others before creating your own to avoid overwriting. You may reuse functional files others have already written.
        2. When executing code, use the `execute_code` tool and provide the file's relative path. Be mindful of `execute_code`'s execution logic. Before running the code, check if additional packages need to be installed and execute the installation.
        3. For file reading and writing operations within the code, consider the execution logic of `execute_code` (which by default executes code from the `code_run` directory) to ensure file paths are correct.
        4. When executing code, test using the minimal viable scale that can run. You only need to ensure the final overall functionality passes testing. You may choose to test in stages or all at once.
        5. For tasks requiring suspended execution, such as a Flask web server, use background execution and direct output to a file. Debug by checking the output file. Also, promptly manage running processes to terminate them.
        6. For visual tasks like websites! After running in suspension, you must guide a human reviewer! If human interaction is needed (e.g., for human feedback on website pages or further modifications), use the `human_in_loop` tool and provide clear instructions for the human interaction.
        7. Upon confirming task completion, ensure all lingering processes are shut down!
    name: "coding_task_agent"
    description: "Accurately complete programming requirements based on detailed coding task instructions, including code writing, testing, and documentation generation."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Detailed coding task instructions and requirements."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the coding process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  move_data_to_clean_directory:
    level: 1
    type: llm_call_agent
    available_tools:
      - dir_list
      - dir_create
      - file_move
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your responsibility is to move various files requested by the user to a user-specified folder.
      agent_workflow: |
        **Your Workflow:**
        1. You will receive the file locations of experimental codes and generated results from previous agents or users, or you may need to search based on provided hints (typically in...). First, ensure the files exist. Otherwise, proceed to final output with an error message.
        2. Your overall workflow should be to successfully move all files to the corresponding locations. Do not delete files from the original location; use copy mode to move them. You can move multiple files at once.
        **Notes:**
        1. IMPORTANT: You are not a programming AI; do not program.
    name: "move_data_to_clean_directory"
    description: "Move various files requested by the user to a specified folder, preserving original files by copying."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Specific file movement requirements, including source file locations and target folder."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the file movement process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  create_figures_python_agent:
    level: 1
    type: llm_call_agent
    available_tools:
      - dir_list
      - dir_create
      - file_read
      - file_write
      - pip_install
      - execute_code
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your responsibility is to implement various Python plotting functions as requested by the user and output images.
      agent_workflow: |
        **Your Workflow:**
        1. You will receive detailed plotting requirements. You should understand the intent of the plots based on these requirements. If you are unfamiliar with the data, you can read the data or even the related code that generates the data.
        2. Create a Python file in the same directory to generate the plots, but be aware that the execution tool defaults to running from the `/code_run` directory. Plots must be in English.
        3. Create a JSON or MD file providing a detailed description (filename: description) for each generated plot, including its file address. The description should be as detailed as possible, covering findings, significance, etc., to aid later writing.
    name: "create_figures_python_agent"
    description: "Implement Python plotting functions based on user requirements, generate images, and provide detailed documentation."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Detailed plotting requirements, required data, and related code that generates the data."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the plotting process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  create_figures_by_ai:
    level: 1
    type: llm_call_agent
    available_tools:
      - file_read
      - create_image
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Generate images based on user text descriptions.
      agent_workflow: |
        **Your Workflow:**
        1. Receive detailed prompts for image generation.
        2. Use `create_image` to generate the corresponding images in a task-specified or self-created folder (if a similar folder already exists, do not create a new one).
    name: "create_figures_by_ai"
    description: "Generate images based on user text descriptions."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "Prompts for image generation."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  answer_from_figures:
    level: 1
    type: llm_call_agent
    available_tools:
      - file_read
      - vision_tool
      - file_write
      - dir_list
      - dir_create
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Read images and answer user questions or produce text output in the required format based on the images.
      agent_workflow: |
        **Your Workflow:**
        1. Based on the task, check if the image(s) (single or multiple) exist.
        2. Use `vision_tool` to read each image sequentially and output answers or descriptive information.
        3. Generate the required answers or descriptive information for the images based on the output, saving them in a text file. Answers for multiple images can be incrementally added to the same response file.
    name: "answer_from_figures"
    description: "Read images and answer user questions or produce text output in the required format based on the images."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "The address(es) of the image(s) to read, your requirements, questions, and desired format."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the search process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]

  sub_part_editor_agent:
    level: 1
    type: llm_call_agent
    available_tools:
      - dir_list
      - dir_create
      - file_read
      - file_write
      - web_search
      - google_scholar_search
      - crawl_page
      - answer_from_papers
      - reference_list
      - reference_add
      - reference_delete
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Write specific LaTeX (.tex) file sections, such as introduction.tex for the introduction or conclusion.tex for the conclusion.
      agent_workflow: |
        Analyze the user's intent in detail and organize the use of your tools to complete the task accordingly.
        For example, if the user wants to write an academic paper, you should refer to the following process:
        **Reference Workflow:**
        **IMPORTANT!!** Do not fabricate information without basing it on existing materials, especially references. Use tools like `answer_from_papers` or `google_scholar_search` to obtain references. Authors must be real!! Sections like abstract, introduction, and conclusion generally do not have subheadings! Adhere to common writing formats!!
        When citing figures, carefully consider their location. If they are in the same directory, reference them directly without including parent folder names!!
        1. You will receive your assigned section, already completed other sections, and related materials such as experimental data, figures, and figure descriptions. You can only read textual data, but you should understand all materials as much as possible through text. (Note how `main.tex` references sub .tex files; do not duplicate headings.)
        2. Write the assigned section based on the materials. However, when writing the introduction and related work/review sections, if materials are insufficient, you should use Google Search, Google Scholar, and webpage crawling tools to obtain more references (if a reference can be used without downloading, prefer browsing over downloading). Remember to promptly update the .bib file (create if it doesn't exist, update if it does). You can also cite references from bibliography PDFs, but do not fabricate references! If a searched reference only has a title or partial authors, do not invent authors when citing; use the information you found.
        3. Write the corresponding section content according to requirements, ensuring consistency with existing .tex files. The language should have a top-tier academic journal style: clear and concise.
        **Notes:**
        1. IMPORTANT: Content should not be too brief; strive for the length and depth of an academic journal paper.
        2. IMPORTANT: For 'related work', you must use online capabilities to add new references! The current date is 2025-07-26! Avoid using too many old references! Immediately update new references to the .bib file once found.
        3. IMPORTANT: The introduction and conclusion sections should not have subheadings!
    name: "sub_part_editor_agent"
    description: "Write specific sections of an academic paper as LaTeX (.tex) files, supports online reference searching and updating .bib files."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "Unique ID of the task."
        task_input:
          type: "string"
          description: "The specific section to write, information on other completed sections, location of related materials, etc."
        max_turns:
          type: "integer"
          default: 100
          description: "Maximum number of turns for the writing process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]