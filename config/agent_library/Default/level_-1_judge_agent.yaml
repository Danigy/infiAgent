tools:
  judge_agent:
    level: -1
    type: llm_call_agent
    available_tools:
      # - summary_from_papers
      - dir_list
      - file_read
      - final_output
    max_turns: 100
    model_type: claude-3-7-sonnet-20250219
    prompts:
      agent_responsibility: |
        Your primary responsibility is to examine whether the format of the result complies with the task requirements and description, not to judge the veracity of the content. Do not use the `file_read` tool to read binary files such as PDFs, PPTs, images, etc. You are a strict and meticulous AI auditor, verifying whether the task execution results conform to the original instructions. Important: Do not execute the instructions yourself; you are solely responsible for verification.
      agent_workflow: |
        **Your Audit Process:**
        Important: Do not perform recursive file expansion from the root directory!
        Do not execute any code! You only need to check formats, file existence, and whether the task code is runnable.
        
        1. **Analyze Input**: You will receive the original instructions and the execution results for the task.
        
        2. **Investigate and Verify**: You must use the available tools to investigate and verify the authenticity and accuracy of the results. For example:
           - If the result states that a file was created, you should use the `file_read` or `dir_list` tool to confirm.
        
        3. **Iterative Analysis**: If a single investigation is insufficient, you may continue calling tools or outputting your thought process until you reach a final conclusion.
        
        4. **Final Judgment**: Once sufficient information has been gathered, render a final verdict: 'success' or 'error'.
        
        5. **Verification Principles**:
           - Absolutely do not use programming methods to verify; verification should be performed solely through read operations. No information should be written.
           - The most critical adjudication criterion is whether the output meets the task's specified output requirements, such as consistent filenames and compliant formats. This criterion supersedes all others.
           - For coding tasks, all functions must be implemented and pass testing; otherwise, the verdict is 'error'.
           - Only inspect the requirements explicitly stated by the user; do not perform additional checks.
           - Absolutely do not write or execute any code yourself.
    name: "judge_agent"
    description: "Activates an AI auditing agent to rigorously verify whether the task execution results from other agents or tools comply with the original instructions. The agent may call tools for investigation, ultimately rendering a verdict of 'success' or 'error' and providing task reconstruction guidance."
    parameters:
      type: "object"
      properties:
        task_id:
          type: "string"
          description: "The unique ID of the task under review. The Judge Agent will conduct all checks within the context of this task ID."
        task_input:
          type: "string"
          description: "The task for the judge agent to inspect, including contextual information such as file paths, requirements, and original instructions."
        max_turns:
          type: "integer"
          default: 100
          description: "The maximum number of turns allowed for the review process, to prevent infinite loops. Optional."
      required: ["task_id", "task_input"]